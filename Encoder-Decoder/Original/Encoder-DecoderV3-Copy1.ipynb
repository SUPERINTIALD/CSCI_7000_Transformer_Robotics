{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aad7875c-b5ba-4c83-98c4-b1ed72cfdfe3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPS device not found. Using CPU.\n"
     ]
    }
   ],
   "source": [
    "# For Mac\n",
    "import torch\n",
    "if torch.backends.mps.is_available():\n",
    "    print(\"MPS device found. Using GPU.\")\n",
    "else:\n",
    "    print(\"MPS device not found. Using CPU.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aebe9c26-132f-4242-9282-21715fa780ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of GPUs available: 1\n",
      "GPU 0: NVIDIA GeForce RTX 4070\n",
      "Active GPU index: 0\n",
      "Active GPU name: NVIDIA GeForce RTX 4070\n"
     ]
    }
   ],
   "source": [
    "# For 4070 \n",
    "import torch\n",
    "import soundfile as sf\n",
    "import torchaudio\n",
    "if torch.cuda.is_available():\n",
    "    # Get the number of available GPUs\n",
    "    gpu_count = torch.cuda.device_count()\n",
    "    print(f\"Number of GPUs available: {gpu_count}\")\n",
    "    \n",
    "    # Iterate through all available GPUs and print their names\n",
    "    for i in range(gpu_count):\n",
    "        print(f\"GPU {i}: {torch.cuda.get_device_name(i)}\")\n",
    "        \n",
    "    # Print the name of the *currently* active GPU (if one is selected)\n",
    "    current_device_index = torch.cuda.current_device()\n",
    "    print(f\"Active GPU index: {current_device_index}\")\n",
    "    print(f\"Active GPU name: {torch.cuda.get_device_name(current_device_index)}\")\n",
    "\n",
    "else:\n",
    "    print(\"CUDA is not available. PyTorch is using the CPU.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "65b6531a-7f97-4017-9ac8-4629a332d0e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torchaudio version: 2.5.0+cu124\n",
      "SoundFile found: version 0.13.1\n",
      "FFmpeg libraries detected (via torchaudio.io)\n",
      "Write Test PASSED: Torchaudio can successfully save audio.\n"
     ]
    }
   ],
   "source": [
    "import torchaudio\n",
    "import soundfile\n",
    "print(f\"Torchaudio version: {torchaudio.__version__}\")\n",
    "\n",
    "print(f\"SoundFile found: version {soundfile.__version__}\")\n",
    "print(\"FFmpeg libraries detected (via torchaudio.io)\")\n",
    "import io\n",
    "buffer = io.BytesIO()\n",
    "# Create 1 second of silence\n",
    "waveform = torch.zeros(1, 16000) \n",
    "torchaudio.save(buffer, waveform, 16000, format=\"wav\", backend=\"soundfile\")\n",
    "print(\"Write Test PASSED: Torchaudio can successfully save audio.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d7fcb867-1056-4d5e-a701-8cfc89b931b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import zipfile\n",
    "\n",
    "# zip_name = \"./machine_biometrics/MLVRG-Car-Engine-Audio.zip\"\n",
    "# # Need to combine the zipped folders\n",
    "\n",
    "# with open(zip_name, 'wb') as combined_zip:\n",
    "#     for i in range(1, 10): \n",
    "#         part_name = f\"{zip_name}.{i:03d}\"\n",
    "#         if os.path.exists(part_name):\n",
    "#             print(f\"Adding {part_name}...\")\n",
    "#             with open(part_name, 'rb') as part_file:\n",
    "#                 combined_zip.write(part_file.read())\n",
    "#         else:\n",
    "#             print(f\"Warning: {part_name} not found.\")\n",
    "\n",
    "# print(\"Combination complete. Extracting now...\")\n",
    "\n",
    "# with zipfile.ZipFile(zip_name, 'r') as zip_ref:\n",
    "#     zip_ref.extractall(\"extracted_data\")\n",
    "\n",
    "# print(\"Done! Check the 'extracted_data' folder in your file browser.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "26629b30-cdc5-43ec-9921-2768c2565897",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folders found:\n",
      " - MLVRG-Car-Engine-Audio\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "base_path = \"./extracted_data\" \n",
    "\n",
    "if os.path.exists(base_path):\n",
    "    print(\"Folders found:\")\n",
    "    for item in os.listdir(base_path):\n",
    "        if os.path.isdir(os.path.join(base_path, item)):\n",
    "            print(f\" - {item}\")\n",
    "else:\n",
    "    print(f\"Could not find path: {base_path}. Check where the zip extracted to.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f456638e-7577-453f-81df-3a4d0b0f5516",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Car Models Found:\n",
      " - AlphaRomeo\n",
      " - BMW\n",
      " - Chevrolet\n",
      " - Citroen\n",
      " - Daewoo\n",
      " - Fiat\n",
      " - Ford\n",
      " - Hyundai\n",
      " - Opel\n",
      " - Peugeot\n",
      " - Renault\n",
      " - Seat\n",
      " - Skoda\n",
      " - Suzuki\n",
      " - Toyota\n",
      " - VolksWagen\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "nested_path = base_path + \"/MLVRG-Car-Engine-Audio\"\n",
    "\n",
    "if os.path.exists(nested_path):\n",
    "    print(\"Car Models Found:\")\n",
    "    for item in sorted(os.listdir(nested_path)):\n",
    "        if os.path.isdir(os.path.join(nested_path, item)) and not item.startswith('.'):\n",
    "            print(f\" - {item}\")\n",
    "else:\n",
    "    print(f\"Still can't find the path: {nested_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cc740b4e-3c0e-4181-8670-c8f7d758a2db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLVRG-Car-Engine-Audio/\n",
      "    AlphaRomeo/\n",
      "        Giulietta/\n",
      "            1000/\n",
      "                0001.wav\n",
      "            1500/\n",
      "                0001.wav\n",
      "            2000/\n",
      "                0001.wav\n",
      "    BMW/\n",
      "        116/\n",
      "            1000/\n",
      "                0001.wav\n",
      "            1500/\n",
      "                0001.wav\n",
      "            2000/\n",
      "                0001.wav\n",
      "        520i/\n",
      "            1000/\n",
      "                0001.wav\n",
      "            1500/\n",
      "                0001.wav\n",
      "            2000/\n",
      "                0001.wav\n",
      "        x6/\n",
      "            1000/\n",
      "                0001.wav\n",
      "            1500/\n",
      "                0001.wav\n",
      "            2000/\n",
      "                0001.wav\n",
      "    Chevrolet/\n",
      "        Lacetti/\n",
      "            1000/\n",
      "                0001.wav\n",
      "            1500/\n",
      "                0001.wav\n",
      "            2000/\n",
      "                0001.wav\n",
      "        Spark/\n",
      "            1000/\n",
      "                0001.wav\n",
      "                0002.wav\n",
      "                0003.wav\n",
      "            2000/\n",
      "                0001.wav\n",
      "                0002.wav\n",
      "                0003.wav\n",
      "    Citroen/\n",
      "        Berlingo/\n",
      "            1000/\n",
      "                0001.wav\n",
      "            1500/\n",
      "                0001.wav\n",
      "            2000/\n",
      "                0001.wav\n",
      "        C2/\n",
      "            1000/\n",
      "                0001.wav\n",
      "            1500/\n",
      "                0001.wav\n",
      "            2000/\n",
      "                0001.wav\n",
      "        C3/\n",
      "            1000/\n",
      "                0001.wav\n",
      "                0002.wav\n",
      "            1500/\n",
      "                0001.wav\n",
      "                0002.wav\n",
      "            2000/\n",
      "                0001.wav\n",
      "                0002.wav\n",
      "        C4/\n",
      "            1000/\n",
      "                0001.wav\n",
      "            1500/\n",
      "                0001.wav\n",
      "            2000/\n",
      "                0001.wav\n",
      "        Saxo/\n",
      "            1000/\n",
      "                0001.wav\n",
      "                0002.wav\n",
      "            1500/\n",
      "                0001.wav\n",
      "                0002.wav\n",
      "            2000/\n",
      "                0001.wav\n",
      "                0002.wav\n",
      "    Daewoo/\n",
      "        Matiz/\n",
      "            1000/\n",
      "                0001.wav\n",
      "            1500/\n",
      "                0001.wav\n",
      "            2000/\n",
      "                0001.wav\n",
      "    Fiat/\n",
      "        Doblo/\n",
      "            1000/\n",
      "                0001.wav\n",
      "            1500/\n",
      "                0001.wav\n",
      "            2000/\n",
      "                0001.wav\n",
      "        Panda/\n",
      "            1000/\n",
      "                0001.wav\n",
      "                0002.wav\n",
      "            1500/\n",
      "                0001.wav\n",
      "                0002.wav\n",
      "            2000/\n",
      "                0001.wav\n",
      "                0002.wav\n",
      "        Punto/\n",
      "            1000/\n",
      "                0001.wav\n",
      "                0002.wav\n",
      "                0003.wav\n",
      "            1500/\n",
      "                0001.wav\n",
      "                0002.wav\n",
      "                0003.wav\n",
      "            2000/\n",
      "                0001.wav\n",
      "                0002.wav\n",
      "                0003.wav\n",
      "    Ford/\n",
      "        Fiesta/\n",
      "            1000/\n",
      "                0001.wav\n",
      "                0002.wav\n",
      "            1500/\n",
      "                0001.wav\n",
      "                0002.wav\n",
      "            2000/\n",
      "                0001.wav\n",
      "                0002.wav\n",
      "        Focus/\n",
      "            1000/\n",
      "                0001.wav\n",
      "                0002.wav\n",
      "                0003.wav\n",
      "            1500/\n",
      "                0001.wav\n",
      "                0002.wav\n",
      "            2000/\n",
      "                0001.wav\n",
      "                0002.wav\n",
      "                0003.wav\n",
      "        KA/\n",
      "            1000/\n",
      "                0001.wav\n",
      "            1500/\n",
      "                0001.wav\n",
      "            2000/\n",
      "                0001.wav\n",
      "        Modeo/\n",
      "            1000/\n",
      "                0001.wav\n",
      "            1500/\n",
      "                0001.wav\n",
      "            2000/\n",
      "                0001.wav\n",
      "    Hyundai/\n",
      "        Atos/\n",
      "            1000/\n",
      "                0001.wav\n",
      "            1500/\n",
      "                0001.wav\n",
      "            2000/\n",
      "                0001.wav\n",
      "        i20/\n",
      "            1000/\n",
      "                0001.wav\n",
      "            1500/\n",
      "                0001.wav\n",
      "            2000/\n",
      "                0001.wav\n",
      "    Opel/\n",
      "        Astra/\n",
      "            1000/\n",
      "                0001.wav\n",
      "                0002.wav\n",
      "                0003.wav\n",
      "                0004.wav\n",
      "            1500/\n",
      "                0001.wav\n",
      "                0002.wav\n",
      "                0003.wav\n",
      "                0004.wav\n",
      "            2000/\n",
      "                0001.wav\n",
      "                0002.wav\n",
      "                0003.wav\n",
      "                0004.wav\n",
      "        Corsa/\n",
      "            1000/\n",
      "                0001.wav\n",
      "                0002.wav\n",
      "            1500/\n",
      "                0001.wav\n",
      "                0002.wav\n",
      "            2000/\n",
      "                0001.wav\n",
      "                0002.wav\n",
      "        Vectra/\n",
      "            1000/\n",
      "                0001.wav\n",
      "            1500/\n",
      "                0001.wav\n",
      "            2000/\n",
      "                0001.wav\n",
      "    Peugeot/\n",
      "        106/\n",
      "            1000/\n",
      "                0001.wav\n",
      "            1500/\n",
      "                0001.wav\n",
      "            2000/\n",
      "                0001.wav\n",
      "        307/\n",
      "            1000/\n",
      "                0001.wav\n",
      "                0002.wav\n",
      "                0003.wav\n",
      "            1500/\n",
      "                0001.wav\n",
      "                0002.wav\n",
      "                0003.wav\n",
      "            2000/\n",
      "                0001.wav\n",
      "                0002.wav\n",
      "                0003.wav\n",
      "    Renault/\n",
      "        Megane/\n",
      "            1000/\n",
      "                0001.wav\n",
      "                0002.wav\n",
      "            1500/\n",
      "                0001.wav\n",
      "                0002.wav\n",
      "            2000/\n",
      "                0001.wav\n",
      "                0002.wav\n",
      "        Twingo/\n",
      "            1000/\n",
      "                0001.wav\n",
      "                0002.wav\n",
      "            1500/\n",
      "                0001.wav\n",
      "                0002.wav\n",
      "            2000/\n",
      "                0001.wav\n",
      "                0002.wav\n",
      "    Seat/\n",
      "        Ibiza/\n",
      "            1000/\n",
      "                0001.wav\n",
      "            1500/\n",
      "                0001.wav\n",
      "            2000/\n",
      "                0001.wav\n",
      "    Skoda/\n",
      "        Octavia/\n",
      "            1000/\n",
      "                0001.wav\n",
      "            1500/\n",
      "                0001.wav\n",
      "            2000/\n",
      "                0001.wav\n",
      "    Suzuki/\n",
      "        GrandVitara/\n",
      "            1000/\n",
      "                0001.wav\n",
      "                0002.wav\n",
      "            1500/\n",
      "                0001.wav\n",
      "                0002.wav\n",
      "            2000/\n",
      "                0001.wav\n",
      "                0002.wav\n",
      "    Toyota/\n",
      "        Yaris/\n",
      "            1000/\n",
      "                0001.wav\n",
      "            1500/\n",
      "                0001.wav\n",
      "            2000/\n",
      "                0001.wav\n",
      "    VolksWagen/\n",
      "        Polo1.4/\n",
      "            1000/\n",
      "                0001.wav\n",
      "            1500/\n",
      "                0001.wav\n",
      "            2000/\n",
      "                0001.wav\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "data_folder = base_path + \"/MLVRG-Car-Engine-Audio\"\n",
    "limit = 10\n",
    "for dirpath, dirnames, filenames in os.walk(data_folder):\n",
    "    depth = dirpath.replace(data_folder, \"\").count(os.sep)\n",
    "    indent = \"    \" * depth\n",
    "    print(f\"{indent}{os.path.basename(dirpath) or data_folder}/\")\n",
    "    # print files\n",
    "    for fname in filenames[:limit]:\n",
    "        print(f\"{indent}    {fname}\")\n",
    "    if len(filenames) > limit:\n",
    "        print(f\"{indent}    ... {len(filenames) - limit} more\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9338e054-bcbc-4aef-9305-c0e416dfd7de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Need to add car specs in terms of engine noise.\n",
    "\n",
    "# car_specs_lookup = {\n",
    "#     # --- Alfa Romeo ---\n",
    "#     \"Giulietta\": {\"engine\": \"I4\", \"aspiration\": \"turbo\", \"cylinders\": 4},\n",
    "    \n",
    "#     # --- BMW ---\n",
    "#     \"116\":  {\"engine\": \"I4\", \"aspiration\": \"natural\", \"cylinders\": 4},\n",
    "#     \"520i\": {\"engine\": \"I6\", \"aspiration\": \"natural\", \"cylinders\": 6},\n",
    "#     \"x6\":   {\"engine\": \"V8\", \"aspiration\": \"turbo\",   \"cylinders\": 8},\n",
    "    \n",
    "#     # --- Chevrolet ---\n",
    "#     \"Lacetti\": {\"engine\": \"I4\", \"aspiration\": \"natural\", \"cylinders\": 4},\n",
    "#     \"Spark\":   {\"engine\": \"I4\", \"aspiration\": \"natural\", \"cylinders\": 4},\n",
    "    \n",
    "#     # --- Citroen ---\n",
    "#     \"C2\":       {\"engine\": \"I4\", \"aspiration\": \"natural\", \"cylinders\": 4},\n",
    "#     \"C3\":       {\"engine\": \"I4\", \"aspiration\": \"natural\", \"cylinders\": 4},\n",
    "#     \"C4\":       {\"engine\": \"I4\", \"aspiration\": \"natural\", \"cylinders\": 4},\n",
    "#     \"Saxo\":     {\"engine\": \"I4\", \"aspiration\": \"natural\", \"cylinders\": 4},\n",
    "#     \"Berlingo\": {\"engine\": \"I4\", \"aspiration\": \"natural\", \"cylinders\": 4},\n",
    "    \n",
    "#     # --- Daewoo ---\n",
    "#     \"Matiz\": {\"engine\": \"I3\", \"aspiration\": \"natural\", \"cylinders\": 3},\n",
    "    \n",
    "#     # --- Fiat ---\n",
    "#     \"Panda\": {\"engine\": \"I4\", \"aspiration\": \"natural\", \"cylinders\": 4},\n",
    "#     \"Punto\": {\"engine\": \"I4\", \"aspiration\": \"natural\", \"cylinders\": 4},\n",
    "#     \"Doblo\": {\"engine\": \"I4\", \"aspiration\": \"natural\", \"cylinders\": 4},\n",
    "    \n",
    "#     # --- Ford ---\n",
    "#     \"Fiesta\": {\"engine\": \"I4\", \"aspiration\": \"natural\", \"cylinders\": 4},\n",
    "#     \"Focus\":  {\"engine\": \"I4\", \"aspiration\": \"natural\", \"cylinders\": 4},\n",
    "#     \"KA\":     {\"engine\": \"I4\", \"aspiration\": \"natural\", \"cylinders\": 4},\n",
    "#     \"Modeo\":  {\"engine\": \"I4\", \"aspiration\": \"natural\", \"cylinders\": 4}, \n",
    "    \n",
    "#     # --- Hyundai ---\n",
    "#     \"Atos\": {\"engine\": \"I4\", \"aspiration\": \"natural\", \"cylinders\": 4},\n",
    "#     \"i20\":  {\"engine\": \"I4\", \"aspiration\": \"natural\", \"cylinders\": 4},\n",
    "    \n",
    "#     # --- Opel ---\n",
    "#     \"Astra\":  {\"engine\": \"I4\", \"aspiration\": \"natural\", \"cylinders\": 4},\n",
    "#     \"Corsa\":  {\"engine\": \"I4\", \"aspiration\": \"natural\", \"cylinders\": 4},\n",
    "#     \"Vectra\": {\"engine\": \"I4\", \"aspiration\": \"natural\", \"cylinders\": 4},\n",
    "    \n",
    "#     # --- Peugeot ---\n",
    "#     \"106\": {\"engine\": \"I4\", \"aspiration\": \"natural\", \"cylinders\": 4},\n",
    "#     \"307\": {\"engine\": \"I4\", \"aspiration\": \"natural\", \"cylinders\": 4},\n",
    "    \n",
    "#     # --- Renault ---\n",
    "#     \"Megane\": {\"engine\": \"I4\", \"aspiration\": \"natural\", \"cylinders\": 4},\n",
    "#     \"Twingo\": {\"engine\": \"I4\", \"aspiration\": \"natural\", \"cylinders\": 4},\n",
    "    \n",
    "#     # --- Seat ---\n",
    "#     \"Ibiza\": {\"engine\": \"I4\", \"aspiration\": \"natural\", \"cylinders\": 4},\n",
    "    \n",
    "#     # --- Skoda ---\n",
    "#     \"Octavia\": {\"engine\": \"I4\", \"aspiration\": \"turbo\",   \"cylinders\": 4},\n",
    "    \n",
    "#     # --- Suzuki ---\n",
    "#     \"GrandVitara\": {\"engine\": \"I4\", \"aspiration\": \"natural\", \"cylinders\": 4},\n",
    "    \n",
    "#     # --- Toyota ---\n",
    "#     \"Yaris\": {\"engine\": \"I4\", \"aspiration\": \"natural\", \"cylinders\": 4},\n",
    "    \n",
    "#     # --- Volkswagen ---\n",
    "#     \"Polo1.4\": {\"engine\": \"I4\", \"aspiration\": \"natural\", \"cylinders\": 4}\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "29dbde05-e519-42c2-8fa8-a7bafa438f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import pandas as pd\n",
    "# import glob\n",
    "\n",
    "# dataset_root = \"./extracted_data/MLVRG-Car-Engine-Audio\" \n",
    "# output_csv = \"engine_data_manifest.csv\"\n",
    "\n",
    "# data_registry = []\n",
    "\n",
    "# if os.path.exists(dataset_root):\n",
    "#     print(\"ðŸ“‚ Scanning folders...\")\n",
    "#     for brand_folder in sorted(os.listdir(dataset_root)):\n",
    "#         brand_path = os.path.join(dataset_root, brand_folder)\n",
    "        \n",
    "#         if not os.path.isdir(brand_path) or brand_folder.startswith('.'):\n",
    "#             continue\n",
    "            \n",
    "#         for model_folder in os.listdir(brand_path):\n",
    "#             model_path = os.path.join(brand_path, model_folder)\n",
    "            \n",
    "#             if not os.path.isdir(model_path) or model_folder.startswith('.'):\n",
    "#                 continue\n",
    "#             lookup_key = model_folder.split(\" \")[0] \n",
    "            \n",
    "#             specs = car_specs_lookup.get(lookup_key, {\"engine\": \"I4\", \"aspiration\": \"natural\", \"cylinders\": 4})\n",
    "            \n",
    "#             wav_files = glob.glob(os.path.join(model_path, \"**/*.wav\"), recursive=True)\n",
    "            \n",
    "#             for file_path in wav_files:\n",
    "#                 data_registry.append({\n",
    "#                     \"path\": file_path,\n",
    "#                     \"brand\": brand_folder,\n",
    "#                     \"model\": model_folder,\n",
    "#                     \"engine_type\": specs[\"engine\"],\n",
    "#                     \"aspiration\": specs[\"aspiration\"],\n",
    "#                     \"cylinders\": specs[\"cylinders\"],\n",
    "#                     \"label\": f\"{specs['engine']} {specs['aspiration']}\" \n",
    "#                 })\n",
    "    \n",
    "#     if len(data_registry) > 0:\n",
    "#         df = pd.DataFrame(data_registry)\n",
    "#         df.to_csv(output_csv, index=False)\n",
    "#         print(f\"Success! Created '{output_csv}' with {len(df)} audio samples.\")\n",
    "#         print(df.head())\n",
    "#     else:\n",
    "#         print(\"No audio files found. Check the 'dataset_root' path.\")\n",
    "\n",
    "# else:\n",
    "#     print(f\"Error: The path '{dataset_root}' does not exist.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0d3879d0-da88-4535-adde-2dbd66df2340",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Train \n",
      "Shape: (152, 7)\n",
      "Columns: ['path', 'brand', 'model', 'engine_type', 'aspiration', 'cylinders', 'label']\n",
      "                                                path       brand      model  \\\n",
      "0  ./extracted_data/MLVRG-Car-Engine-Audio\\AlphaR...  AlphaRomeo  Giulietta   \n",
      "1  ./extracted_data/MLVRG-Car-Engine-Audio\\AlphaR...  AlphaRomeo  Giulietta   \n",
      "2  ./extracted_data/MLVRG-Car-Engine-Audio\\AlphaR...  AlphaRomeo  Giulietta   \n",
      "3  ./extracted_data/MLVRG-Car-Engine-Audio\\BMW\\11...         BMW        116   \n",
      "4  ./extracted_data/MLVRG-Car-Engine-Audio\\BMW\\11...         BMW        116   \n",
      "\n",
      "  engine_type aspiration  cylinders       label  \n",
      "0          I4      turbo          4    I4 turbo  \n",
      "1          I4      turbo          4    I4 turbo  \n",
      "2          I4      turbo          4    I4 turbo  \n",
      "3          I4    natural          4  I4 natural  \n",
      "4          I4    natural          4  I4 natural  \n",
      "Missing values:\n",
      " path           0\n",
      "brand          0\n",
      "model          0\n",
      "engine_type    0\n",
      "aspiration     0\n",
      "cylinders      0\n",
      "label          0\n",
      "dtype: int64\n",
      "Description train:          cylinders\n",
      "count  152.000000\n",
      "mean     4.098684\n",
      "std      0.638291\n",
      "min      3.000000\n",
      "25%      4.000000\n",
      "50%      4.000000\n",
      "75%      4.000000\n",
      "max      8.000000\n",
      "Type path             str\n",
      "brand            str\n",
      "model            str\n",
      "engine_type      str\n",
      "aspiration       str\n",
      "cylinders      int64\n",
      "label            str\n",
      "dtype: object\n",
      "<class 'pandas.DataFrame'>\n",
      "RangeIndex: 152 entries, 0 to 151\n",
      "Data columns (total 7 columns):\n",
      " #   Column       Non-Null Count  Dtype\n",
      "---  ------       --------------  -----\n",
      " 0   path         152 non-null    str  \n",
      " 1   brand        152 non-null    str  \n",
      " 2   model        152 non-null    str  \n",
      " 3   engine_type  152 non-null    str  \n",
      " 4   aspiration   152 non-null    str  \n",
      " 5   cylinders    152 non-null    int64\n",
      " 6   label        152 non-null    str  \n",
      "dtypes: int64(1), str(6)\n",
      "memory usage: 8.4 KB\n",
      "Info None\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_df = pd.read_csv('./engine_data_manifest.csv')\n",
    "\n",
    "\n",
    "print(\"\\n Train \")\n",
    "print(\"Shape:\", train_df.shape)\n",
    "print(\"Columns:\", list(train_df.columns))\n",
    "print(train_df.head())\n",
    "print(\"Missing values:\\n\", train_df.isnull().sum())\n",
    "print(\"Description train: \", train_df.describe())\n",
    "print(\"Type\", train_df.dtypes)\n",
    "print(\"Info\", train_df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b373987f-1abb-48a4-b23f-af6749137aa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded with 152 samples.\n",
      "Spectrogram Shape: torch.Size([1, 64, 63]) (Channels, Frequency, Time)\n",
      "Label: I4 turbo\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchaudio\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# class EngineAudioDataset(Dataset):\n",
    "#     def __init__(self, csv_file, target_sample_rate=16000, fixed_duration=5.0):\n",
    "#         self.annotations = pd.read_csv(csv_file)\n",
    "#         self.target_sample_rate = target_sample_rate\n",
    "#         self.num_samples = int(target_sample_rate * fixed_duration) # e.g., 5s * 16000 = 80,000 samples\n",
    "        \n",
    "#         # Define the transformation (Audio Waveform -> Mel Spectrogram Image)\n",
    "#         self.mel_spectrogram = torchaudio.transforms.MelSpectrogram(\n",
    "#             sample_rate=target_sample_rate,\n",
    "#             n_mels=64,  # Height of the image\n",
    "#             n_fft=1024,\n",
    "#             hop_length=512\n",
    "#         )\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return len(self.annotations)\n",
    "\n",
    "#     def __getitem__(self, index):\n",
    "#         audio_sample_path = self.annotations.iloc[index]['path']\n",
    "#         if not os.path.exists(audio_sample_path):\n",
    "#              audio_sample_path = audio_sample_path.replace(\"./\", \"\") \n",
    "             \n",
    "#         label = self.annotations.iloc[index]['label']\n",
    "        \n",
    "#         # 2. Load Audio\n",
    "#         waveform, sr = torchaudio.load(audio_sample_path)\n",
    "        \n",
    "#         # 3. Resample if needed (Standardize to 16k)\n",
    "#         if sr != self.target_sample_rate:\n",
    "#             resampler = torchaudio.transforms.Resample(sr, self.target_sample_rate)\n",
    "#             waveform = resampler(waveform)\n",
    "            \n",
    "#         # 4. Mix down to Mono (if stereo)\n",
    "#         if waveform.shape[0] > 1:\n",
    "#             waveform = torch.mean(waveform, dim=0, keepdim=True)\n",
    "            \n",
    "#         # 5. Fix Length (Pad if short, Cut if long)\n",
    "#         if waveform.shape[1] > self.num_samples:\n",
    "#             waveform = waveform[:, :self.num_samples] # Cut\n",
    "#         elif waveform.shape[1] < self.num_samples:\n",
    "#             padding = self.num_samples - waveform.shape[1]\n",
    "#             waveform = torch.nn.functional.pad(waveform, (0, padding)) # Pad with zeros\n",
    "#         # if hasattr(self, 'is_training') and self.is_training:\n",
    "#         #     noise = torch.randn_like(waveform) * 0.005 \n",
    "#         #     waveform = waveform + noise    \n",
    "#         # 6. Convert to Mel Spectrogram\n",
    "#         mel_spec = self.mel_spectrogram(waveform)\n",
    "        \n",
    "#         # Log scaling (makes features more visible like a picture)\n",
    "#         mel_spec = torch.log(mel_spec + 1e-9)\n",
    "\n",
    "#         return mel_spec, label\n",
    "class EngineAudioDataset(Dataset):\n",
    "    def __init__(self, dataframe, target_sample_rate=16000, segment_duration=2.0, is_train=True):\n",
    "        self.annotations = dataframe # Pass the split dataframe (train or val)\n",
    "        self.target_sample_rate = target_sample_rate\n",
    "        # We define a shorter segment length (e.g., 2 seconds)\n",
    "        self.segment_samples = int(target_sample_rate * segment_duration) \n",
    "        self.is_train = is_train\n",
    "        \n",
    "        self.mel_spectrogram = torchaudio.transforms.MelSpectrogram(\n",
    "            sample_rate=target_sample_rate,\n",
    "            n_mels=64,\n",
    "            n_fft=1024,\n",
    "            hop_length=512\n",
    "        )\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.annotations)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        row = self.annotations.iloc[index]\n",
    "        audio_sample_path = row['path'].replace(\"./\", \"\")\n",
    "        label = row['label']\n",
    "        \n",
    "        # 1. Load the full audio file\n",
    "        # Using soundfile + torch.from_numpy is safer for segmenting\n",
    "        waveform, sr = sf.read(audio_sample_path)\n",
    "        waveform = torch.from_numpy(waveform).float()\n",
    "        if waveform.ndim == 1: waveform = waveform.unsqueeze(0)\n",
    "        else: waveform = waveform.t()\n",
    "\n",
    "        # 2. Resample if needed\n",
    "        if sr != self.target_sample_rate:\n",
    "            resampler = torchaudio.transforms.Resample(sr, self.target_sample_rate)\n",
    "            waveform = resampler(waveform)\n",
    "\n",
    "        # 3. SEGMENTATION (The Random Windowing Trick)\n",
    "        # Instead of fixed length, we grab a random chunk of the file\n",
    "        if waveform.shape[1] > self.segment_samples:\n",
    "            if self.is_train:\n",
    "                # Pick a random starting point\n",
    "                max_start = waveform.shape[1] - self.segment_samples\n",
    "                start = random.randint(0, max_start)\n",
    "            else:\n",
    "                # Validation is always consistent (starts at 0)\n",
    "                start =0\n",
    "            waveform = waveform[:, start:start + self.segment_samples]\n",
    "        else:\n",
    "            # If the file is too short, pad it\n",
    "            padding = self.segment_samples - waveform.shape[1]\n",
    "            waveform = torch.nn.functional.pad(waveform, (0, padding))\n",
    "\n",
    "        # 4. Mix to Mono\n",
    "        if waveform.shape[0] > 1:\n",
    "            waveform = torch.mean(waveform, dim=0, keepdim=True)\n",
    "            \n",
    "        # 5. Optional: Add a tiny bit of noise during training\n",
    "        # if self.is_train:\n",
    "        #     waveform = waveform + (torch.randn_like(waveform) * 0.005)\n",
    "        # Inside EngineAudioDataset.__getitem__ (training only)\n",
    "        if self.is_train:\n",
    "            # Randomly change volume between 80% and 120%\n",
    "            waveform = waveform * (random.uniform(0.8, 1.2))\n",
    "            # Add slightly more white noise\n",
    "            waveform = waveform + (torch.randn_like(waveform) * 0.01)\n",
    "\n",
    "\n",
    "            \n",
    "        # 6. Convert to Mel Spectrogram\n",
    "        mel_spec = self.mel_spectrogram(waveform)\n",
    "        mel_spec = torch.log(mel_spec + 1e-9)\n",
    "\n",
    "        return mel_spec, label\n",
    "# Test it out!\n",
    "# dataset = EngineAudioDataset(csv_file=\"engine_data_manifest.csv\")\n",
    "import random\n",
    "import pandas as pd\n",
    "manifest_df = pd.read_csv(\"engine_data_manifest.csv\")\n",
    "\n",
    "# 2. Initialize the dataset using the DataFrame\n",
    "dataset = EngineAudioDataset(manifest_df)\n",
    "print(f\"Dataset loaded with {len(dataset)} samples.\")\n",
    "\n",
    "# Get one sample to check shape\n",
    "spec, lbl = dataset[0]\n",
    "print(f\"Spectrogram Shape: {spec.shape} (Channels, Frequency, Time)\")\n",
    "print(f\"Label: {lbl}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d8370de1-ea30-493c-a1b6-775b39aa1697",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets start Training lOl\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_model, num_heads):\n",
    "        super().__init__()\n",
    "        assert d_model % num_heads == 0, \"d_model must be divisible by num_heads\"\n",
    "        \n",
    "        self.d_model = d_model\n",
    "        self.num_heads = num_heads\n",
    "        self.d_k = d_model // num_heads\n",
    "        \n",
    "        # Linear layers for Q, K, V\n",
    "        self.W_q = nn.Linear(d_model, d_model, bias=False)\n",
    "        self.W_k = nn.Linear(d_model, d_model, bias=False)\n",
    "        self.W_v = nn.Linear(d_model, d_model, bias=False)\n",
    "        self.W_o = nn.Linear(d_model, d_model, bias=False)\n",
    "        \n",
    "    def forward(self, q, k, v, mask=None):\n",
    "        batch_size = q.size(0)\n",
    "        \n",
    "        # 1. Linear Projections & Split into Heads\n",
    "        # Shape: (Batch, Seq_Len, Num_Heads, Head_Dim)\n",
    "        Q = self.W_q(q).view(batch_size, -1, self.num_heads, self.d_k).transpose(1, 2)\n",
    "        K = self.W_k(k).view(batch_size, -1, self.num_heads, self.d_k).transpose(1, 2)\n",
    "        V = self.W_v(v).view(batch_size, -1, self.num_heads, self.d_k).transpose(1, 2)\n",
    "        \n",
    "        # 2. Scaled Dot-Product Attention\n",
    "        # (Batch, Heads, Q_Len, K_Len)\n",
    "        scores = torch.matmul(Q, K.transpose(-2, -1)) / math.sqrt(self.d_k)\n",
    "        \n",
    "        if mask is not None:\n",
    "            scores = scores.masked_fill(mask, float('-inf'))        \n",
    "        attn_weights = F.softmax(scores, dim=-1)\n",
    "        \n",
    "        # 3. Apply Attention to Values\n",
    "        output = torch.matmul(attn_weights, V)\n",
    "        \n",
    "        # 4. Concatenate Heads & Final Linear\n",
    "        # Shape: (Batch, Seq_Len, d_model)\n",
    "        output = output.transpose(1, 2).contiguous().view(batch_size, -1, self.d_model)\n",
    "        return self.W_o(output)\n",
    "\n",
    "class PositionwiseFeedForward(nn.Module):\n",
    "    def __init__(self, d_model, d_ff, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(d_model, d_ff),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(d_ff, d_model)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e3cc027a-0593-4a7c-a707-31395f354774",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerEncoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, num_heads, d_ff, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.self_attn = MultiHeadAttention(d_model, num_heads)\n",
    "        self.feed_forward = PositionwiseFeedForward(d_model, d_ff, dropout)\n",
    "        \n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, x, mask=None):\n",
    "        # 1. Self Attention sub-layer\n",
    "        attn_output = self.self_attn(x, x, x, mask)\n",
    "        x = self.norm1(x + self.dropout(attn_output))\n",
    "        \n",
    "        # 2. Feed Forward sub-layer\n",
    "        ff_output = self.feed_forward(x)\n",
    "        x = self.norm2(x + self.dropout(ff_output))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9fca91a1-6b51-4a0b-bc94-710fc19489bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerDecoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, num_heads, d_ff, dropout=0.1):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Masked Self-Attention (Target looking at Target)\n",
    "        self.self_attn = MultiHeadAttention(d_model, num_heads)\n",
    "        \n",
    "        # Cross-Attention (Target looking at Audio Source)\n",
    "        self.cross_attn = MultiHeadAttention(d_model, num_heads)\n",
    "        \n",
    "        self.feed_forward = PositionwiseFeedForward(d_model, d_ff, dropout)\n",
    "        \n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "        self.norm3 = nn.LayerNorm(d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, x, enc_output, src_mask=None, tgt_mask=None):\n",
    "        # 1. Masked Self-Attention\n",
    "        # x = text input\n",
    "        attn_out = self.self_attn(x, x, x, tgt_mask) \n",
    "        x = self.norm1(x + self.dropout(attn_out))\n",
    "        \n",
    "        # 2. Cross-Attention (Query = x, Key/Value = Encoder Output)\n",
    "        # This is where Audio meets Text\n",
    "        cross_out = self.cross_attn(x, enc_output, enc_output, src_mask)\n",
    "        x = self.norm2(x + self.dropout(cross_out))\n",
    "        \n",
    "        # 3. Feed Forward\n",
    "        ff_out = self.feed_forward(x)\n",
    "        x = self.norm3(x + self.dropout(ff_out))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7ab2b50c-6ce0-4d41-9819-2f527e95e021",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AudioEngineTransformer(nn.Module):\n",
    "    def __init__(self, num_classes, d_model=128, num_heads=4, num_layers=2, d_ff=512):\n",
    "        super().__init__()\n",
    "        \n",
    "        # --- ENCODER (Audio Side) ---\n",
    "        # Projects 64 mel-bins to d_model (128)\n",
    "        self.audio_projection = nn.Linear(64, d_model) \n",
    "        self.pos_encoding = nn.Parameter(torch.randn(1, 1000, d_model)) # Simplified Positional Encoding\n",
    "        \n",
    "        self.encoder_layers = nn.ModuleList([\n",
    "            TransformerEncoderLayer(d_model, num_heads, d_ff) for _ in range(num_layers)\n",
    "        ])\n",
    "        \n",
    "        # --- DECODER (Text Side) ---\n",
    "        # Embeds text tokens (V8, Turbo, BMW)\n",
    "        self.text_embedding = nn.Embedding(num_classes, d_model)\n",
    "        \n",
    "        self.decoder_layers = nn.ModuleList([\n",
    "            TransformerDecoderLayer(d_model, num_heads, d_ff) for _ in range(num_layers)\n",
    "        ])\n",
    "        \n",
    "        # Final prediction layer\n",
    "        self.fc_out = nn.Linear(d_model, num_classes)\n",
    "        self.d_model = d_model\n",
    "\n",
    "    def forward(self, src_audio, tgt_text, tgt_mask=None):\n",
    "        # --- Encode Audio ---\n",
    "        # src_audio shape: (Batch, Time, 64)\n",
    "        src = self.audio_projection(src_audio) \n",
    "        src = src + self.pos_encoding[:, :src.size(1), :] # Add position info\n",
    "        \n",
    "        # Run through Encoder Layers\n",
    "        enc_output = src\n",
    "        for layer in self.encoder_layers:\n",
    "            enc_output = layer(enc_output)\n",
    "            \n",
    "        # --- Decode Text ---\n",
    "        # tgt_text shape: (Batch, Seq_Len)\n",
    "        tgt = self.text_embedding(tgt_text) \n",
    "        tgt = tgt + self.pos_encoding[:, :tgt.size(1), :]\n",
    "        # Run through Decoder Layers\n",
    "        dec_output = tgt\n",
    "        for layer in self.decoder_layers:\n",
    "            # Note: We pass enc_output to every decoder layer for Cross-Attention\n",
    "            dec_output = layer(dec_output, enc_output, tgt_mask=tgt_mask)\n",
    "            \n",
    "        # Final prediction\n",
    "        output = self.fc_out(dec_output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dd6b0ab5-1c3a-4264-8d6e-b72ff745fc07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train files: 121 | Val files: 31\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load original 152-sample manifest\n",
    "df = pd.read_csv('engine_data_manifest.csv')\n",
    "# Split UNIQUE files 80/20\n",
    "train_df, val_df = train_test_split(df, test_size=0.2, stratify=df['label'], random_state=42)\n",
    "\n",
    "print(f\"Train files: {len(train_df)} | Val files: {len(val_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "90c37252-51f8-42d8-968e-0429e954d044",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary Size: 9\n",
      "Vocab: {'<pad>': 0, '<sos>': 1, '<eos>': 2, 'I3': 3, 'I4': 4, 'I6': 5, 'V8': 6, 'natural': 7, 'turbo': 8}\n",
      "Train batches: 31 | Val batches: 4\n",
      "DataLoader now has 31 batches.\n",
      "Batch Audio Shape: torch.Size([8, 1, 64, 63])\n",
      "Batch Text Shape: torch.Size([8, 4])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fungy\\AppData\\Local\\Temp\\ipykernel_22168\\475803650.py:50: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\torch\\csrc\\utils\\tensor_numpy.cpp:212.)\n",
      "  weights=torch.DoubleTensor(sample_weights),\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import WeightedRandomSampler\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "all_words = set()\n",
    "\n",
    "for label in train_df['label']:\n",
    "    all_words.update(label.split()) # Splits \"I4 natural\" into [\"I4\", \"natural\"]\n",
    "\n",
    "# Special tokens\n",
    "vocab = {\"<pad>\": 0, \"<sos>\": 1, \"<eos>\": 2}\n",
    "for i, word in enumerate(sorted(all_words)):\n",
    "    vocab[word] = i + 3\n",
    "\n",
    "print(f\"Vocabulary Size: {len(vocab)}\")\n",
    "print(f\"Vocab: {vocab}\")\n",
    "\n",
    "# 2. Define the Collate Function\n",
    "# This function runs every time the DataLoader grabs a batch.\n",
    "# It handles turning text into numbers and padding them so they are all the same length.\n",
    "def audio_text_collate_fn(batch):\n",
    "    audio_batch = []\n",
    "    text_batch = []\n",
    "    \n",
    "    for audio, label_text in batch:\n",
    "        audio_batch.append(audio)\n",
    "        \n",
    "        # Convert text to indices: <sos> + tokens + <eos>\n",
    "        tokens = [vocab[\"<sos>\"]] + [vocab[w] for w in label_text.split()] + [vocab[\"<eos>\"]]\n",
    "        text_batch.append(torch.tensor(tokens))\n",
    "        \n",
    "    # Stack Audio (already padded in Dataset class) -> (Batch, Freq, Time)\n",
    "    audio_batch = torch.stack(audio_batch)\n",
    "    \n",
    "    # Pad Text Sequences (Batch, Seq_Len)\n",
    "    text_batch = pad_sequence(text_batch, batch_first=True, padding_value=vocab[\"<pad>\"])\n",
    "    \n",
    "    return audio_batch, text_batch\n",
    "\n",
    "# 3. Create the DataLoader\n",
    "\n",
    "# 1. Calculate weights for the TRAIN set only\n",
    "counts = train_df['label'].value_counts()\n",
    "weights = 1.0 / counts\n",
    "sample_weights = train_df['label'].map(weights).values\n",
    "\n",
    "# 2. Create the Sampler\n",
    "sampler = WeightedRandomSampler(\n",
    "    weights=torch.DoubleTensor(sample_weights),\n",
    "    num_samples=len(sample_weights) * 2, # Artificially double the epoch to see more variations\n",
    "    replacement=True\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "train_dataset = EngineAudioDataset(train_df, is_train=True)\n",
    "val_dataset = EngineAudioDataset(val_df, is_train=False)\n",
    "\n",
    "# 5. Create DataLoaders\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, batch_size=8, sampler=sampler, collate_fn=audio_text_collate_fn\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_dataset, batch_size=8, shuffle=False, collate_fn=audio_text_collate_fn\n",
    ")\n",
    "\n",
    "print(f\"Train batches: {len(train_loader)} | Val batches: {len(val_loader)}\")\n",
    "print(f\"DataLoader now has {len(train_loader)} batches.\")\n",
    "# Test one batch\n",
    "audio_sample, text_sample = next(iter(train_loader))\n",
    "print(f\"Batch Audio Shape: {audio_sample.shape}\") # Should be (8, 64, 313) approx\n",
    "print(f\"Batch Text Shape: {text_sample.shape}\")   # Should be (8, Seq_Len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6fea4ed4-5561-486a-8350-98bc081765df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def generate_square_subsequent_mask(sz):\n",
    "#     \"\"\"\n",
    "#     Generates an upper-triangular matrix of -inf, with zeros on diag.\n",
    "#     This prevents the model from attending to future positions.\n",
    "#     \"\"\"\n",
    "#     mask = (torch.triu(torch.ones(sz, sz)) == 1).transpose(0, 1)\n",
    "#     mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
    "#     return mask\n",
    "\n",
    "def generate_square_subsequent_mask(sz, device=None):\n",
    "    # Returns a Boolean matrix: \n",
    "    # False (0) for positions we keep, True (1) for positions we mask\n",
    "    mask = torch.triu(torch.ones(sz, sz, device=device), diagonal=1).bool()\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c801b9ad-7973-4c7c-b94e-a382e5ee7dab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on: cuda\n",
      "Epoch [1/20] Loss: 1.5218\n",
      "Epoch [2/20] Loss: 0.9112\n",
      "Epoch [3/20] Loss: 0.8147\n",
      "Epoch [4/20] Loss: 0.7152\n",
      "Epoch [5/20] Loss: 0.6617\n",
      "Epoch [6/20] Loss: 0.6035\n",
      "Epoch [7/20] Loss: 0.6027\n",
      "Epoch [8/20] Loss: 0.5610\n",
      "Epoch [9/20] Loss: 0.5455\n",
      "Epoch [10/20] Loss: 0.5463\n",
      "Epoch [11/20] Loss: 0.5472\n",
      "Epoch [12/20] Loss: 0.5311\n",
      "Epoch [13/20] Loss: 0.5185\n",
      "Epoch [14/20] Loss: 0.5170\n",
      "Epoch [15/20] Loss: 0.5055\n",
      "Epoch [16/20] Loss: 0.5115\n",
      "Epoch [17/20] Loss: 0.5168\n",
      "Epoch [18/20] Loss: 0.5162\n",
      "Epoch [19/20] Loss: 0.5085\n",
      "Epoch [20/20] Loss: 0.5044\n",
      "Training Complete!\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# 1. Hyperparameters\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Training on: {device}\")\n",
    "\n",
    "# Model Setup\n",
    "model = AudioEngineTransformer(\n",
    "    num_classes=len(vocab), # Size of our vocabulary\n",
    "    d_model=128,            # Must match your class definition\n",
    "    num_heads=4, \n",
    "    num_layers=2\n",
    ").to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=vocab[\"<pad>\"], label_smoothing=0.1)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=30, gamma=0.1)\n",
    "# 2. Training Loop\n",
    "num_epochs = 20\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    \n",
    "    for batch_idx, (audio, text) in enumerate(train_loader):\n",
    "        audio = audio.to(device) # Shape: (Batch, 64, Time)\n",
    "        text = text.to(device)   # Shape: (Batch, Seq_Len) e.g., [<sos>, I4, turbo, <eos>]\n",
    "        \n",
    "        # Prepare Inputs and Targets for Teacher Forcing\n",
    "        # Decoder Input: <sos>, I4, turbo   (remove last token)\n",
    "        tgt_input = text[:, :-1]\n",
    "        \n",
    "        # Target Output: I4, turbo, <eos>   (remove first token)\n",
    "        tgt_output = text[:, 1:]\n",
    "        \n",
    "        # Create Mask for Decoder\n",
    "        seq_len = tgt_input.size(1)\n",
    "        tgt_mask = generate_square_subsequent_mask(seq_len).to(device)\n",
    "        \n",
    "        # --- Forward Pass ---\n",
    "        # Note: audio needs to be permuted for the Linear layer in Encoder\n",
    "        # Current: (Batch, 64, Time) -> Target for Linear: (Batch, Time, 64)\n",
    "        audio_squeezed = audio.squeeze(1)\n",
    "        audio_in = audio_squeezed.permute(0, 2, 1)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Run Model\n",
    "        output = model(audio_in, tgt_input, tgt_mask)\n",
    "        # Output shape: (Batch, Seq_Len, Vocab_Size)\n",
    "        \n",
    "        # --- Calculate Loss ---\n",
    "        # Flatten outputs and targets for CrossEntropy\n",
    "        loss = criterion(output.reshape(-1, len(vocab)), tgt_output.reshape(-1))\n",
    "        \n",
    "        # --- Backward Pass ---\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "    scheduler.step()\n",
    "        \n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}] Loss: {total_loss / len(train_loader):.4f}\")\n",
    "\n",
    "print(\"Training Complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0b031757-08c6-45cf-9b21-97d5bfa604ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw tokens: [1, 6]\n",
      "Raw tokens: [1, 6, 8]\n",
      "Raw tokens: [1, 6, 8, 2]\n",
      "Original Label: V8 turbo\n",
      "Model Prediction: V8 turbo\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    # 1. Grab a random sample\n",
    "    audio, label_text = dataset[10]\n",
    "    audio = audio.unsqueeze(0).to(device)\n",
    "    \n",
    "    # 2. Prepare Encoder Input\n",
    "    audio_squeezed = audio.squeeze(1)\n",
    "    audio_in = audio_squeezed.permute(0, 2, 1)\n",
    "    \n",
    "    # 3. Greedy Decoding (Decoder predicts one word at a time)\n",
    "    input_tokens = [vocab[\"<sos>\"]]\n",
    "    for _ in range(5):  # Max 5 words\n",
    "        tgt_tensor = torch.tensor([input_tokens]).to(device)\n",
    "        output = model(audio_in, tgt_tensor)\n",
    "        \n",
    "        # Get the word with highest probability\n",
    "        next_token = output[0, -1].argmax().item()\n",
    "        input_tokens.append(next_token)\n",
    "        \n",
    "        if next_token == vocab[\"<eos>\"]:\n",
    "            break\n",
    "        print(f\"Raw tokens: {input_tokens}\")\n",
    "    print(f\"Raw tokens: {input_tokens}\")\n",
    "    # 4. Convert indices back to words\n",
    "    rev_vocab = {v: k for k, v in vocab.items()}\n",
    "    prediction = \" \".join([rev_vocab[t] for t in input_tokens if t not in [0, 1, 2]])\n",
    "    \n",
    "    print(f\"Original Label: {label_text}\")\n",
    "    print(f\"Model Prediction: {prediction}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "666b0d13-2fed-4d38-b03c-83f22c951bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.eval()\n",
    "# correct_sequences = 0\n",
    "# total_sequences = 0\n",
    "\n",
    "# print(\"Calculating accuracy on dataset...\")\n",
    "\n",
    "# with torch.no_grad():\n",
    "#     for audio, text in train_loader:\n",
    "#         audio = audio.to(device)\n",
    "#         text = text.to(device)\n",
    "        \n",
    "#         # Prepare Encoder Input\n",
    "#         audio_in = audio.squeeze(1).permute(0, 2, 1)\n",
    "        \n",
    "#         # Batch decoding\n",
    "#         for i in range(audio.size(0)):\n",
    "#             input_tokens = [vocab[\"<sos>\"]]\n",
    "#             single_audio = audio_in[i:i+1]\n",
    "            \n",
    "#             # Target (ground truth) without special tokens for comparison\n",
    "#             target_indices = text[i].tolist()\n",
    "#             target_label = [t for t in target_indices if t not in [0, 1, 2]]\n",
    "            \n",
    "#             for _ in range(5):\n",
    "#                 tgt_tensor = torch.tensor([input_tokens]).to(device)\n",
    "#                 output = model(single_audio, tgt_tensor)\n",
    "#                 next_token = output[0, -1].argmax().item()\n",
    "#                 input_tokens.append(next_token)\n",
    "#                 if next_token == vocab[\"<eos>\"]:\n",
    "#                     break\n",
    "            \n",
    "#             # Predicted without special tokens\n",
    "#             predicted_label = [t for t in input_tokens if t not in [0, 1, 2]]\n",
    "            \n",
    "#             if predicted_label == target_label:\n",
    "#                 correct_sequences += 1\n",
    "#             total_sequences += 1\n",
    "\n",
    "# accuracy = (correct_sequences / total_sequences) * 100\n",
    "# print(f\"\\n--- Final Results ---\")\n",
    "# print(f\"Total Samples Tested: {total_sequences}\")\n",
    "# print(f\"Sequence Accuracy: {accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "738f9d44-bdd4-4564-8efa-90be16998a06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Sequence Accuracy: 98.35%\n",
      "Validation Sequence Accuracy: 90.32%\n"
     ]
    }
   ],
   "source": [
    "def check_accuracy(loader, name=\"Dataset\"):\n",
    "    model.eval()\n",
    "    correct_sequences = 0\n",
    "    total_sequences = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for audio, text in loader:\n",
    "            audio, text = audio.to(device), text.to(device)\n",
    "            audio_in = audio.squeeze(1).permute(0, 2, 1)\n",
    "            \n",
    "            for i in range(audio.size(0)):\n",
    "                input_tokens = [vocab[\"<sos>\"]]\n",
    "                single_audio = audio_in[i:i+1]\n",
    "                \n",
    "                # Get target (removing <pad>, <sos>, <eos>)\n",
    "                target_label = [t for t in text[i].tolist() if t not in [0, 1, 2]]\n",
    "                \n",
    "                # Greedy Decoding\n",
    "                for _ in range(5):\n",
    "                    tgt_tensor = torch.tensor([input_tokens]).to(device)\n",
    "                    output = model(single_audio, tgt_tensor)\n",
    "                    next_token = output[0, -1].argmax().item()\n",
    "                    input_tokens.append(next_token)\n",
    "                    if next_token == vocab[\"<eos>\"]: break\n",
    "                \n",
    "                predicted_label = [t for t in input_tokens if t not in [0, 1, 2]]\n",
    "                if predicted_label == target_label:\n",
    "                    correct_sequences += 1\n",
    "                total_sequences += 1\n",
    "                \n",
    "    accuracy = (correct_sequences / total_sequences) * 100\n",
    "    print(f\"{name} Sequence Accuracy: {accuracy:.2f}%\")\n",
    "\n",
    "# Check both to see if you are overfitting\n",
    "check_accuracy(train_loader, \"Training\")\n",
    "check_accuracy(val_loader, \"Validation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9fcb0f3-08e1-4967-8d54-445fd1638875",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
